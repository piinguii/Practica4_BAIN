# Practica4
## Olivia Troiti√±o, Claudia Gasc√≥, Alberto Martin
README separado en dos secciones.
1. Dev (comentarios durante el development de la pr√°ctica)
2. Entrega (informaci√≥n README est√°ndar)

## Dev
### üë• Organizaci√≥n del trabajo (3 personas)
```
üîπ Persona A: Obtenci√≥n y preprocesamiento de datos
    Extraer al menos 10 rese√±as reales (pueden ser m√°s).
    Etiquetarlas manualmente o tomar rese√±as con calificaci√≥n (1 estrella = negativa, 5 estrellas = positiva).
    Guardarlas en un archivo .csv o .json.
    Opcional: crear un peque√±o notebook para dejar documentado el paso (cuenta como ‚ÄúNotebook extractor de datos inicial‚Äù).
üîπ Persona B: Dise√±o de prompts y ejecuci√≥n
    Crear 3 prompts por t√©cnica.
    Ejecutar los prompts en al menos 3 modelos distintos de Hugging Face.
üîπ Persona C: Evaluaci√≥n y presentaci√≥n
    Comparar resultados entre modelos y entre tipos de prompts.
    Medir: precisi√≥n, coherencia, errores frecuentes, etc.
    Redactar el an√°lisis de resultados, incluyendo:
        Qu√© prompts funcionaron mejor
        Qu√© modelo fue m√°s acertado o r√°pido
        Qu√© dificultades tuvieron
    Armar la presentaci√≥n (PowerPoint o PDF).
```
**Persona B (Olivia): Prompts y Ejecuci√≥n**
- Tengo un prompt por cada t√©cnica, todas corren pero la √∫ltima (CoT) da todo negativo en los primeros dos modelos.
#TODO armar dos prompts m√°s por cada t√©cnica
#TODO reevaluar el prompt de CoT para ver si no lo estoy guiando a lo negativo O ALTERNATIVAMENTE reevaluar si son los modelos correctos para la pr√°ctica.

### Teor√≠a Prompt Engineering
- **Zero-shot** prompting means that the prompt used to interact with the model won't contain examples or demonstrations. The zero-shot prompt directly instructs the model to perform a task without any additional examples to steer it.
    Example: 
    ``` Prompt:
            Classify the text into neutral, negative or positive. 
            Text: I think the vacation is okay.
            Sentiment:
        Output:
            Neutral```
- **Few-shot** prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance.
    Example:
    ``` Prompt: 
            A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:
            We were traveling in Africa and we saw these very cute whatpus.
            To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
        Output:
            When we won the game, we all started to farduddle in celebration.```
    We can observe that the model has somehow learned how to perform the task by providing it with just one example (i.e., 1-shot). For more difficult tasks, we can experiment with increasing the demonstrations (e.g., 3-shot, 5-shot, 10-shot, etc.).
- **Chain-of-thought** (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding.
    Example:
    ``` Prompt:
            The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
            A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.

            The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.
            A: Adding all the odd numbers (17, 19) gives 36. The answer is True.

            The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.
            A: 
        Output:
            Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.```



## Entrega
### Librer√≠as
```
%pip install datasets
%pip install transformers
%pip install pandas
%pip install tensorflow
%pip install torch
%pip install tf-keras
%pip install os
```
### LLMs Testeados
1. `siebert/sentiment-roberta-large-english`
- Clasifica rese√±as en positivo y negativo. Solo funciona para "raw text", hay que darle solamente la rese√±a. Por lo tanto, no aplica a ninguno de los tipos de prompt engineering.
2. `nlptown/bert-base-multilingual-uncased-sentiment`
- Clasifica rese√±as de 1 a 5 estrellas.
3. `google/flan-t5-base`
- 

### Instrucciones:

Objetivo: Aplicar modelos de tipo Large Language Models (LLMs) para extraer conocimiento.
Formaci√≥n de grupos: Trabajar en grupos de hasta 4 personas y documentar los nombres en un README.md.
Exploraci√≥n de modelos:

Utilizar al menos tantos modelos de LLM como participantes en el grupo.
Los modelos pueden ser del repositorio de Hugging Face o de una API p√∫blica.

### Pruebas de prompts:

Probar al menos tres tipos de prompts:
- Zero-shot (solo explicaci√≥n).
- Few-shots (explicaci√≥n con ejemplos).
- Chain of thoughts (razonamiento del resultado).

Selecci√≥n del problema: Elegir un problema validable o con m√©trica num√©rica (ejemplos: detecci√≥n de copia, correcci√≥n autom√°tica de ex√°menes, detecci√≥n de spam, extracci√≥n de contactos, ‚Ä¶).
Aplicaci√≥n del sistema: Aplicar el sistema a m√°s de una fuente de datos o documentos (al menos 10).

### Entrega:

Crear un Jupyter Notebook aplicable en Google Colab, incluyendo modelos, prompts explicados, ejecutados y evaluados.
Preparar una presentaci√≥n para exponer el √∫ltimo d√≠a de clase, explicando el problema, los mejores prompts y modelos, y un resumen de los resultados con conclusiones.

### Evaluaci√≥n:

- Exploraci√≥n de modelos de tipo LLM y t√©cnicas de prompt engineering justificadas. (3 puntos)
- Evaluaci√≥n y justificaci√≥n de los resultados del prompt engineering. (2 puntos)
- Presentaci√≥n. (4 puntos)
- Limpieza y calidad general. (1 punto)

### Entregables:

- Jupyter Notebook extractor de datos inicial (OPCIONAL).
- Carpeta con los datos de entrada INPUT.
- Jupyter Notebook principal con modelos, prompts y evaluaci√≥n.
- Presentaci√≥n que se expone en clase

### Notas:

- La pr√°ctica se puede realizar en grupos de m√°ximo 4 personas. Los nombres y apellidos de los integrantes del grupo han de aparecer en la primera l√≠nea de un fichero llamado ‚ÄúREADME.md‚Äù entregado con la pr√°ctica. Si no aparece dicha l√≠nea, se considera que la pr√°ctica fue realizada de manera individual por la persona que entreg√≥ la pr√°ctica (con las implicaciones correspondientes de control de copia).
- Los compa√±eros de la pr√°ctica que no se presenten el d√≠a de la presentaci√≥n, obtienen un cero en la parte correspondiente de la presentaci√≥n. Es decir, la nota de su pr√°ctica estar√° acotada por un 6.
- Los alumnos que entreguen una pr√°ctica que d√© un error no controlado o no documentado (en un fichero llamado ‚ÄúREADME.md‚Äù), estar√° autom√°ticamente suspensa con un cero. Entre estos errores se consideran los siguientes:
- Excepciones que no se atrapan ni se documentan.
- Errores de codificaci√≥n.
- Errores de importaci√≥n del c√≥digo como librer√≠a.
- Las entregas fuera de la fecha final de la pr√°ctica se consideran suspensas y su valoraci√≥n ser√° un cero.
- Las entregas que empleen librer√≠as no vistas en clase, han de documentar las librer√≠as que hay que instalar y el comando con el que se instalan en un fichero aparte llamado ‚ÄúREADME.md‚Äù. Si aparecen librer√≠as no vistas en clase sin ser documentadas en este fichero, el valor de la pr√°ctica ser√° de cero.