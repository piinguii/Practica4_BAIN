# Practica4

## Olivia Troiti√±o, Claudia Gasc√≥, Alberto Martin

```
üë• Organizaci√≥n del trabajo (3 personas)
üîπ Persona A: Obtenci√≥n y preprocesamiento de datos
    Extraer al menos 10 rese√±as reales (pueden ser m√°s).
    Etiquetarlas manualmente o tomar rese√±as con calificaci√≥n (1 estrella = negativa, 5 estrellas = positiva).
    Guardarlas en un archivo .csv o .json.
    Opcional: crear un peque√±o notebook para dejar documentado el paso (cuenta como ‚ÄúNotebook extractor de datos inicial‚Äù).
üîπ Persona B: Dise√±o de prompts y ejecuci√≥n
    Crear 3 prompts por t√©cnica.
    Ejecutar los prompts en al menos 3 modelos distintos de Hugging Face.
üîπ Persona C: Evaluaci√≥n y presentaci√≥n
    Comparar resultados entre modelos y entre tipos de prompts.
    Medir: precisi√≥n, coherencia, errores frecuentes, etc.
    Redactar el an√°lisis de resultados, incluyendo:
        Qu√© prompts funcionaron mejor
        Qu√© modelo fue m√°s acertado o r√°pido
        Qu√© dificultades tuvieron
    Armar la presentaci√≥n (PowerPoint o PDF).
```

El objetivo de esta pr√°ctica es *demostrar la capacidad de aplicar modelos de tipo Large Language Models (LLMs) para extraer conocimiento*. Los estudiantes deber√°n utilizar un LLM, ya sea descargado o a trav√©s de una API p√∫blica, y *dise√±ar un prompt adecuado utilizando t√©cnicas de prompt engineering*. Este proceso permitir√° la automatizaci√≥n del procesamiento de informaci√≥n, la generaci√≥n de un reporte y la evaluaci√≥n de la calidad del resultado.

La pr√°ctica puede realizarse en grupos de hasta 4 personas, cuyos nombres deben estar claramente indicados en un documento README.md. Durante la realizaci√≥n de la pr√°ctica, ser√° necesario explorar el funcionamiento de al menos tantos modelos de tipo LLM como participantes en el grupo. Estos modelos pueden ser del repositorio de Hugging Face o de una API p√∫blica. Adem√°s, se deben probar al menos tres tipos de prompts, cada uno utilizando una t√©cnica de prompt engineering: zero-shot (solo explicaci√≥n), few-shots (explicaci√≥n con ejemplos) y chain of thoughts (razonamiento del resultado).

### Librer√≠as utilizadas:
```
%pip install datasets
%pip install transformers
%pip install pandas
%pip install tensorflow
%pip install torch
%pip install tf-keras
%pip install os
```

### LLMs seleccionados:
1. `siebert/sentiment-roberta-large-english`
- Clasifica rese√±as en positivo y negativo.
2. `nlptown/bert-base-multilingual-uncased-sentiment`
- Clasifica de 1 a 5 estrellas.
3. `cardiffnlp/twitter-roberta-base-sentiment`
- Clasifica positivo, neutro o negativo.

### Teor√≠a prompt engineering:
- **Zero-shot** prompting means that the prompt used to interact with the model won't contain examples or demonstrations. The zero-shot prompt directly instructs the model to perform a task without any additional examples to steer it.
    Example: 
    ``` Prompt:
            Classify the text into neutral, negative or positive. 
            Text: I think the vacation is okay.
            Sentiment:
        Output:
            Neutral```
- **Few-shot** prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance.
    Example:
    ``` Prompt: 
            A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:
            We were traveling in Africa and we saw these very cute whatpus.
            To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
        Output:
            When we won the game, we all started to farduddle in celebration.```
    We can observe that the model has somehow learned how to perform the task by providing it with just one example (i.e., 1-shot). For more difficult tasks, we can experiment with increasing the demonstrations (e.g., 3-shot, 5-shot, 10-shot, etc.).
- **Chain-of-thought** (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding.
    Example:
    ``` Prompt:
            The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
            A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.

            The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.
            A: Adding all the odd numbers (17, 19) gives 36. The answer is True.

            The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.
            A: 
        Output:
            Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.```


El *problema a resolver* es libre, pero debe ser validable como correctamente resuelto o no, o tener alg√∫n tipo de m√©trica num√©rica. Algunas ideas incluyen la detecci√≥n de copia en pr√°cticas, la correcci√≥n autom√°tica de ex√°menes de programaci√≥n, la detecci√≥n de spam, la extracci√≥n de contactos de una p√°gina web ... Es importante que el sistema se pueda aplicar a m√°s de una fuente de datos o documentos (al menos 10), permitiendo el conteo del n√∫mero de aciertos o una nota media de calidad si la evaluaci√≥n es num√©rica.

El problema a resolver es un an√°lisis de rese√±as de Amazon, las estrellas que el usuario le da al producto (1-5) y el sentimiento (negativo, neutro, positivo).

La pr√°ctica se entregar√° en forma de Jupyter Notebook, que debe ser aplicable en Google Colab. En el Jupyter Notebook deben aparecer los modelos a descargar, los prompts explicados, ejecutados y evaluados. Adem√°s, se debe preparar una presentaci√≥n para exponer el √∫ltimo d√≠a de clase, explicando el problema, los prompts y modelos que mejor funcionaron, y un resumen de los resultados obtenidos con conclusiones finales.

### Instrucciones:

Objetivo: Aplicar modelos de tipo Large Language Models (LLMs) para extraer conocimiento.
Formaci√≥n de grupos: Trabajar en grupos de hasta 4 personas y documentar los nombres en un README.md.
Exploraci√≥n de modelos:

Utilizar al menos tantos modelos de LLM como participantes en el grupo.
Los modelos pueden ser del repositorio de Hugging Face o de una API p√∫blica.

### Pruebas de prompts:

Probar al menos tres tipos de prompts:
- Zero-shot (solo explicaci√≥n).
- Few-shots (explicaci√≥n con ejemplos).
- Chain of thoughts (razonamiento del resultado).

Selecci√≥n del problema: Elegir un problema validable o con m√©trica num√©rica (ejemplos: detecci√≥n de copia, correcci√≥n autom√°tica de ex√°menes, detecci√≥n de spam, extracci√≥n de contactos, ‚Ä¶).
Aplicaci√≥n del sistema: Aplicar el sistema a m√°s de una fuente de datos o documentos (al menos 10).

### Entrega:

Crear un Jupyter Notebook aplicable en Google Colab, incluyendo modelos, prompts explicados, ejecutados y evaluados.
Preparar una presentaci√≥n para exponer el √∫ltimo d√≠a de clase, explicando el problema, los mejores prompts y modelos, y un resumen de los resultados con conclusiones.

### Evaluaci√≥n:

- Exploraci√≥n de modelos de tipo LLM y t√©cnicas de prompt engineering justificadas. (3 puntos)
- Evaluaci√≥n y justificaci√≥n de los resultados del prompt engineering. (2 puntos)
- Presentaci√≥n. (4 puntos)
- Limpieza y calidad general. (1 punto)

### Entregables:

- Jupyter Notebook extractor de datos inicial (OPCIONAL).
- Carpeta con los datos de entrada INPUT.
- Jupyter Notebook principal con modelos, prompts y evaluaci√≥n.
- Presentaci√≥n que se expone en clase

### Notas:

- La pr√°ctica se puede realizar en grupos de m√°ximo 4 personas. Los nombres y apellidos de los integrantes del grupo han de aparecer en la primera l√≠nea de un fichero llamado ‚ÄúREADME.md‚Äù entregado con la pr√°ctica. Si no aparece dicha l√≠nea, se considera que la pr√°ctica fue realizada de manera individual por la persona que entreg√≥ la pr√°ctica (con las implicaciones correspondientes de control de copia).
- Los compa√±eros de la pr√°ctica que no se presenten el d√≠a de la presentaci√≥n, obtienen un cero en la parte correspondiente de la presentaci√≥n. Es decir, la nota de su pr√°ctica estar√° acotada por un 6.
- Los alumnos que entreguen una pr√°ctica que d√© un error no controlado o no documentado (en un fichero llamado ‚ÄúREADME.md‚Äù), estar√° autom√°ticamente suspensa con un cero. Entre estos errores se consideran los siguientes:
- Excepciones que no se atrapan ni se documentan.
- Errores de codificaci√≥n.
- Errores de importaci√≥n del c√≥digo como librer√≠a.
- Las entregas fuera de la fecha final de la pr√°ctica se consideran suspensas y su valoraci√≥n ser√° un cero.
- Las entregas que empleen librer√≠as no vistas en clase, han de documentar las librer√≠as que hay que instalar y el comando con el que se instalan en un fichero aparte llamado ‚ÄúREADME.md‚Äù. Si aparecen librer√≠as no vistas en clase sin ser documentadas en este fichero, el valor de la pr√°ctica ser√° de cero.